# master_thesis_project1
Azerbaijani Sign Language Real-Time Hand Gesture Transformation using Machine Learning approach

Communicating through hand gestures with each other is simply called the language of signs or sign language.
It is language for communication among deaf and dumb people in the society. At present, sign language is not popular communications method among hearing people, so that the majority of the hearing are not willing to have a talk with the deaf-mute, or they have to spend much time and energy trying to figure out what the correct meaning is. 
Sign Language Recognition, which aims to translate sign language to people who know few about it in the form of text or speech, can be said to be a great help to deaf-mute and hearing people to communicate. As verbal language, each nation has its own specific sign language. 
In this project a real-time vision-based static hand gesture recognition system for Azerbaijani sign language will be developed based on Machine Learning method. The system will contribute to develop or improve similar systems with more signs, such as words, sentences and will lead to improve communication and collaboration among deaf-dumb and hearing people in Azerbaijani society.


Technologies is going to be used - Jupiter platform, Python language with Deep learning, particularly Convolutional Neural Networking methods.
